{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "#i \"nuget: https://pkgs.dev.azure.com/dotnet/TorchSharp/_packaging/Testing%40Local/nuget/v3/index.json\"\n",
    "#r \"nuget: TorchSharp-cpu,0.93.7\"\n",
    "using TorchSharp;\n",
    "using static TorchSharp.TensorExtensionMethods;\n",
    "using static TorchSharp.torch.distributions;\n",
    "\n",
    "using Microsoft.DotNet.Interactive.Formatting;\n",
    "Formatter.SetPreferredMimeTypeFor(typeof(torch.Tensor), \"text/plain\");\n",
    "Formatter.Register<torch.Tensor>((torch.Tensor x) => x.ToString(true));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Numbers and Distributions\n",
    "\n",
    "There is a rich set of random number generation APIs in TorchSharp. We've already seen the ones that are easiest to use: randn(), rand(), and randint(). Normal and uniform distributions are the foundation for many other random number features.\n",
    "\n",
    "In the `TorchSharp.torch.distributions` static class, there is a much richer collection of distributions. Unlike the three basic generators, these generators are organized as classes that you call a method named `sample()` to get a bunch of random number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the seed\n",
    "\n",
    "Like most random number libraries, TorchSharp allows you to set the seed used for random number generation. One peculiarity about TorchSharp is that using the same initial seed will not lead to the same sequence of numbers when using a CPU vs. a GPU. You cannot reproduce results you had on a CPU by running things on a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "torch.random.manual_seed(4711);\n",
    "torch.rand(10).print();\n",
    "torch.random.manual_seed(17);\n",
    "torch.rand(10).print();\n",
    "torch.random.manual_seed(4711);\n",
    "torch.rand(10).print();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coin Toss\n",
    "\n",
    "For example, to get a single-value sample of the Bernoulli distrubtion, which is a binary false/true, 0/1, yes/no, heads/tails generator, you do the following, passing in the probability of the result being '1':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "var bern = Bernoulli(torch.tensor(0.5f));\n",
    "bern.sample().item<float>()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The element type of the sample will be determined by the element type of the probability tensor, so using precise number literal syntax is important.\n",
    "\n",
    "Usually, you want more than one value, you want a tensor-full of them. `sample()` takes as its arguments the size of the dimensions of the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "bern.sample(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "var bin = Binomial(torch.tensor(100), torch.tensor(0.25f));\n",
    "bin.sample().item<float>()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin.sample(3,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "source": [
    "## Categories\n",
    "\n",
    "In the coin toss scenario, there were two categories -- yes/no, true/false, 0/1, etc. A more general class of distributions support N different categories. The foundational class for that is called 'Categorical,' and it works just like Bernoulli. You tell it how many categories there are, the probabilities for those categories (it doesn't have to be even), and then you get your sample. The length of the probabilities tensor tells the Categorical class how many categories there are. The categories are represented as integers in the range [0..N[."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "var cat = Categorical(torch.tensor(new float[]{0.1f, 0.7f, 0.1f, 0.1f}));\n",
    "cat.sample(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a class corresponding to 'Binomial' for categorical distributions. Here, the category is denoted by the index into the tensor. For sample sizes of at least one dimension, the innermost dimension (the last index) representes the category. In other words, each row is a sample, each column is a category. The value in each cell is how many times (out of the total count specified) that the category was selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "var mult = Multinomial(100, new float[]{0.1f, 0.7f, 0.1f, 0.1f});\n",
    "mult.sample().print();\n",
    "mult.sample(5).print();\n",
    "mult.sample(2,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-valued Distributions\n",
    "\n",
    "The majority of random distributions are concerned with real numbers, parameteried by either a min/max range, or the mean and standard deviation, or parameters specific to a distribution.\n",
    "\n",
    "The normal, a.k.a. Gaussian, distribution is the familiar bell-curve, where the likelihood of a value being selected is much higher closer to the mean. \n",
    "\n",
    "With 'torch.randn()' and 'torch.rand()', the mean is always zero, and the standard deviation always one. To alter them, you get the sample, multiply by the desired standard deviation, then add the desired mean (in that order).\n",
    "\n",
    "You can still do that when you are using the distribution classes, but they also allow you to pass in the parameters when creating the distribution class. This is convenient when you are passing the distribution to a function, which doesn't necessarily have to know anything about what kind of distrubition it is given, or its parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "torch.Tensor foo(Distribution dist) { return dist.sample(4,4);}\n",
    "\n",
    "var norm1 = Normal(torch.tensor(0.5f), torch.tensor(0.125f));\n",
    "var norm2 = Normal(torch.tensor(0.15f), torch.tensor(0.025f));\n",
    "\n",
    "foo(norm1).print();\n",
    "foo(norm2).print();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same goes for uniformly distributed numbers -- there's a class parameterized by the boundaries: [low,high]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "var uni = Uniform(torch.tensor(10.0f), torch.tensor(17.0f));\n",
    "foo(uni)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "name": "C#"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
